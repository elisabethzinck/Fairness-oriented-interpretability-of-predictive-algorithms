Starting bash script
Loaded dependency [python3/3.8.11]: gcc/10.3.0-binutils-2.36.1
Loaded module: python3/3.8.11

Loading python3/3.8.11
  Loading requirement: gcc/10.3.0-binutils-2.36.1
----------------------------
--- Output from Python -----
----------------------------
Global seed set to 42
Using cache found in /zhome/63/6/117697/.cache/torch/hub/pytorch_vision_v0.10.0
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | DenseNet | 7.0 M 
-----------------------------------
1.0 K     Trainable params
7.0 M     Non-trainable params
7.0 M     Total params
27.820    Total estimated model params size (MB)
--- Initializing model ---
--- Training model ---
Params to learn:
	 classifier.weight
	 classifier.bias
Global seed set to 42
Total time to run script: 14.44 mins
----------------------------
---       DONE :)      -----
----------------------------

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11096512: <test_model> in cluster <dcc> Done

Job <test_model> was submitted from host <gbarlogin1> by user <s164204> in cluster <dcc> at Thu Nov 18 14:02:26 2021
Job was executed on host(s) <8*n-62-11-15>, in queue <gpuv100>, as user <s164204> in cluster <dcc> at Thu Nov 18 14:02:52 2021
</zhome/63/6/117697> was used as the home directory.
</zhome/63/6/117697/Documents/Fairness-oriented-interpretability-of-predictive-algorithms> was used as the working directory.
Started at Thu Nov 18 14:02:52 2021
Terminated at Thu Nov 18 14:17:32 2021
Results reported at Thu Nov 18 14:17:32 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh 
### General options 
### -- specify queue -- 
#BSUB -q gpuv100
### -- set the job Name --  (should be the same as in script)
#BSUB -J test_model
### -- ask for number of cores (default: 1) -- 
#BSUB -n 8 
### --- ask for gpu ---
#BSUB -gpu "num=1"
### -- specify that the cores must be on the same host -- 
#BSUB -R "span[hosts=1]"
### -- amount of memory per core/slot -- 
#BSUB -R "rusage[mem=10GB]"
### -- job gets killed if it exceeds xGB per core/slot -- 
#BSUB -M 10GB
### -- set walltime limit: hh:mm -- 
#BSUB -W 02:00 
### -- Specify the output and error file. %J is the job-id -- 
### -- -o and -e mean append, -oo and -eo mean overwrite -- 
#BSUB -oo logs/test_model.out 

echo "Starting bash script"

### Activate environment
module load python3/3.8.11
source .venv/bin/activate

### Run python script
echo "----------------------------"
echo "--- Output from Python -----"
echo "----------------------------"

python3 src/models/cheXpert_neural_network.py

echo "----------------------------"
echo "---       DONE :)      -----"
echo "----------------------------"
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3152.33 sec.
    Max Memory :                                 4845 MB
    Average Memory :                             4050.00 MB
    Total Requested Memory :                     81920.00 MB
    Delta Memory :                               77075.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              18
    Max Threads :                                65
    Run time :                                   880 sec.
    Turnaround time :                            906 sec.

The output (if any) is above this job summary.

